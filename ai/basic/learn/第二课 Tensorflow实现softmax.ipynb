{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials import mnist\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0924 16:32:50.322103 140294744270656 deprecation.py:323] From <ipython-input-3-3bb742cec026>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0924 16:32:50.331631 140294744270656 deprecation.py:323] From /work/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0924 16:32:50.430320 140294744270656 deprecation.py:323] From /work/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "W0924 16:33:05.187274 140294744270656 deprecation.py:323] From /work/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /data/mnist/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0924 16:33:06.260242 140294744270656 deprecation.py:323] From /work/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0924 16:33:06.266845 140294744270656 deprecation.py:323] From /work/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /data/mnist/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /data/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0924 16:33:09.736088 140294744270656 deprecation.py:323] From /work/anaconda3/envs/ai/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /data/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist_data = mnist.input_data.read_data_sets('/data/mnist', one_hot=True) # one_hot 是 y是否one-hot表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train image shape:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'label y shape'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display('train image shape:')\n",
    "display(mnist_data.train.images.shape)\n",
    "display('label y shape')\n",
    "display(mnist_data.train.labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.01176471, 0.54509807, 1.        , 0.9960785 , 0.9960785 ,\n",
       "       0.80392164, 0.4784314 , 0.30980393, 0.06666667, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.23529413, 0.86666673, 0.9921569 ,\n",
       "       0.9960785 , 0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "       0.95294124, 0.14901961, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.5019608 ,\n",
       "       0.97647065, 0.9921569 , 0.8235295 , 0.18823531, 0.06666667,\n",
       "       0.14901961, 0.7294118 , 0.9921569 , 0.6509804 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.43529415, 0.9725491 , 0.9921569 , 0.70980394,\n",
       "       0.13725491, 0.        , 0.        , 0.        , 0.7372549 ,\n",
       "       0.9921569 , 0.50980395, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03137255, 0.6862745 ,\n",
       "       0.9921569 , 0.69411767, 0.03921569, 0.        , 0.        ,\n",
       "       0.        , 0.44705886, 0.97647065, 0.6039216 , 0.07058824,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.5019608 , 0.9921569 , 0.7372549 , 0.04313726,\n",
       "       0.        , 0.        , 0.        , 0.13333334, 0.9568628 ,\n",
       "       0.7725491 , 0.02352941, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.09411766, 0.9176471 ,\n",
       "       0.9294118 , 0.18431373, 0.        , 0.        , 0.        ,\n",
       "       0.03529412, 0.7058824 , 0.9294118 , 0.2784314 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.34901962, 0.9921569 , 0.5686275 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.33333334, 0.87843144,\n",
       "       0.12156864, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54901963,\n",
       "       0.9921569 , 0.3019608 , 0.        , 0.        , 0.        ,\n",
       "       0.01568628, 0.90196085, 0.57254905, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3137255 , 0.9921569 , 0.8431373 ,\n",
       "       0.2627451 , 0.        , 0.        , 0.34509805, 0.7803922 ,\n",
       "       0.01176471, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.63529414, 0.9960785 , 0.9960785 , 0.9725491 ,\n",
       "       0.6509804 , 0.7686275 , 0.89019614, 0.43921572, 0.12941177,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.19607845,\n",
       "       0.67058825, 0.9921569 , 0.9921569 , 0.9921569 , 0.9921569 ,\n",
       "       0.9960785 , 0.9921569 , 0.9725491 , 0.81568635, 0.03921569,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03529412, 0.22352943,\n",
       "       0.41176474, 0.7490196 , 0.9921569 , 0.8352942 , 0.81568635,\n",
       "       0.9921569 , 0.9921569 , 0.654902  , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.3803922 ,\n",
       "       0.9215687 , 0.03529412, 0.03137255, 0.10196079, 0.40784317,\n",
       "       0.8196079 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3803922 , 0.7058824 , 0.        ,\n",
       "       0.        , 0.        , 0.20784315, 0.6392157 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.3803922 , 0.9921569 , 0.0509804 , 0.        , 0.        ,\n",
       "       0.5372549 , 0.3137255 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.22352943, 0.9921569 ,\n",
       "       0.3803922 , 0.        , 0.19215688, 0.8078432 , 0.02745098,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.01176471, 0.7568628 , 0.81568635, 0.29411766,\n",
       "       0.654902  , 0.49803925, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.30980393, 0.9843138 , 0.9921569 , 0.7372549 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.30980393,\n",
       "       0.79215693, 0.12941177, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 从上面可以看出一个image是 1*784的一维向量, label是10个分类中的一个\n",
    "# 再来看看一个图像究竟是张的什么样子\n",
    "\n",
    "def plot_mnist(image_array):\n",
    "    \"\"\"\n",
    "    根据手写识别的数组来进行输出最终的手写识别图片\n",
    "    :param image_array: 手写识别m*n数组\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    fig = plt.figure()\n",
    "    plt.imshow(image_array, cmap='gray')\n",
    "    plt.show()\n",
    "\n",
    "image_index = 7 # 取第一章图片看看\n",
    "image = mnist_data.train.images[image_index]\n",
    "image = image.reshape(28, 28)\n",
    "\n",
    "plot_mnist(image)\n",
    "\n",
    "# 看看label\n",
    "display(mnist_data.train.labels[image_index])\n",
    "# 看看image\n",
    "display(mnist_data.train.images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[0]: Average loss: 0.367622\n",
      "epoch[1]: Average loss: 0.294849\n",
      "epoch[2]: Average loss: 0.283259\n",
      "epoch[3]: Average loss: 0.278080\n",
      "epoch[4]: Average loss: 0.274398\n",
      "epoch[5]: Average loss: 0.272623\n",
      "epoch[6]: Average loss: 0.268660\n",
      "epoch[7]: Average loss: 0.269568\n",
      "epoch[8]: Average loss: 0.266202\n",
      "epoch[9]: Average loss: 0.265703\n",
      "epoch[10]: Average loss: 0.265389\n",
      "epoch[11]: Average loss: 0.263992\n",
      "epoch[12]: Average loss: 0.264202\n",
      "epoch[13]: Average loss: 0.258923\n",
      "epoch[14]: Average loss: 0.261778\n",
      "epoch[15]: Average loss: 0.258597\n",
      "epoch[16]: Average loss: 0.258555\n",
      "epoch[17]: Average loss: 0.256601\n",
      "epoch[18]: Average loss: 0.253446\n",
      "epoch[19]: Average loss: 0.259059\n",
      "epoch[20]: Average loss: 0.256029\n",
      "epoch[21]: Average loss: 0.254039\n",
      "epoch[22]: Average loss: 0.256295\n",
      "epoch[23]: Average loss: 0.254212\n",
      "epoch[24]: Average loss: 0.253880\n",
      "epoch[25]: Average loss: 0.253731\n",
      "epoch[26]: Average loss: 0.253134\n",
      "epoch[27]: Average loss: 0.252340\n",
      "epoch[28]: Average loss: 0.250974\n",
      "epoch[29]: Average loss: 0.252212\n",
      "epoch[30]: Average loss: 0.250308\n",
      "epoch[31]: Average loss: 0.251896\n",
      "epoch[32]: Average loss: 0.253999\n",
      "epoch[33]: Average loss: 0.250774\n",
      "epoch[34]: Average loss: 0.253742\n",
      "epoch[35]: Average loss: 0.250012\n",
      "epoch[36]: Average loss: 0.250824\n",
      "epoch[37]: Average loss: 0.251895\n",
      "epoch[38]: Average loss: 0.249797\n",
      "epoch[39]: Average loss: 0.246970\n",
      "epoch[40]: Average loss: 0.251087\n",
      "epoch[41]: Average loss: 0.253512\n",
      "epoch[42]: Average loss: 0.248899\n",
      "epoch[43]: Average loss: 0.249013\n",
      "epoch[44]: Average loss: 0.251942\n",
      "epoch[45]: Average loss: 0.245865\n",
      "epoch[46]: Average loss: 0.251148\n",
      "epoch[47]: Average loss: 0.247918\n",
      "epoch[48]: Average loss: 0.246496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0924 16:53:48.551287 140294744270656 deprecation.py:323] From <ipython-input-10-ff31dcecb8fc>:52: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.math.argmax` instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[49]: Average loss: 0.250773\n",
      "Accuracy: 0.917500\n"
     ]
    }
   ],
   "source": [
    "# 1. 创建place_holder\n",
    "batch_size = 128 # 每次放入128个图片进行训练\n",
    "image_shape = 784\n",
    "label_shape = 10\n",
    "\n",
    "X = tf.placeholder(tf.float32, [batch_size, image_shape], name='X')\n",
    "Y = tf.placeholder(tf.float32, [batch_size, label_shape], name='Y')\n",
    "\n",
    "# 2 创建权重和参数变量\n",
    "w = tf.Variable(tf.random_normal(shape=(image_shape, label_shape), stddev=0.01), name='weight')\n",
    "b = tf.Variable(tf.zeros([1, 10]), name='bias')\n",
    "\n",
    "# X*w + b = label  所以, 每一个x.shape=1*784, w = 784*10.\n",
    "\n",
    "# 3 前向函数\n",
    "logit = tf.matmul(X, w) + b\n",
    "\n",
    "# 4 loss 函数\n",
    "entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=Y, name='loss')\n",
    "loss = tf.reduce_mean(entropy)\n",
    "\n",
    "# 5 准备优化器\n",
    "learning_rate = 0.01\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "\n",
    "\n",
    "epoch_num = 50 # 训练50轮\n",
    "\n",
    "with tf.Session() as session:\n",
    "\n",
    "    writer = tf.summary.FileWriter('./graph/softmax', session.graph)\n",
    "\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    n_batches = int(mnist_data.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(epoch_num):\n",
    "        total_loss = 0 \n",
    "        for _ in range(n_batches):\n",
    "            X_batch, Y_batch = mnist_data.train.next_batch(batch_size)\n",
    "\n",
    "            _, l = session.run([optimizer, loss], \n",
    "                               feed_dict={X: X_batch, Y: Y_batch})\n",
    "\n",
    "            total_loss += l\n",
    "        print ('epoch[%d]: Average loss: %f' % (i, total_loss/n_batches))\n",
    "\n",
    "        \n",
    "    # 构建预测图\n",
    "    pred = tf.nn.softmax(logit)\n",
    "    correct_preds = tf.equal(tf.arg_max(pred, 1), tf.arg_max(Y, 1))\n",
    "\n",
    "    accuracy = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "\n",
    "    test_n_batches = int(mnist_data.test.num_examples / batch_size)\n",
    "\n",
    "    total_pred_correct = 0\n",
    "    for i in range(test_n_batches):\n",
    "        X_batch_test, Y_batch_test = mnist_data.test.next_batch(batch_size)\n",
    "        accuracy_batch = session.run([accuracy], \n",
    "                                     feed_dict={X: X_batch_test,\n",
    "                                                Y: Y_batch_test})\n",
    "        total_pred_correct += accuracy_batch[0]\n",
    "\n",
    "    print ('Accuracy: %f' % (total_pred_correct / mnist_data.test.num_examples))\n",
    "\n",
    "    writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai)",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
